{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext()\n",
    "session = SparkSession.builder.appName(\"GeminiData\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "def to_spark_df(fin):\n",
    "    data = pd.read_csv(fin)\n",
    "    data.fillna(\"\", inplace=True)\n",
    "    # Remove the html tags\n",
    "    data = data.replace(\"<[^>]*>\", \"\", regex=True)\n",
    "    return(data)\n",
    "\n",
    "# Load the train-test sets\n",
    "train = to_spark_df(\"seed.csv\")\n",
    "test = to_spark_df(\"input_data.csv\")\n",
    "# Remove the unnamed columns\n",
    "test = test.drop(test.columns[[17, 18, 19]],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the  the schema for train and test datasets\n",
    "mySchema = StructType([ StructField(\"_Id\", StringType(), True)\\\n",
    "                       ,StructField(\"_PostTypeId\", StringType(), True)\\\n",
    "                       ,StructField(\"_CreationDate\", StringType(), True)\\\n",
    "                       ,StructField(\"_Score\", StringType(), True)\\\n",
    "                       ,StructField(\"_ViewCount\", StringType(), True)\\\n",
    "                       ,StructField(\"_Body\", StringType(), True)\\\n",
    "                       ,StructField(\"_OwnerUserId\", StringType(), True)\\\n",
    "                       ,StructField(\"_LastActivityDate\", StringType(), True)\\\n",
    "                       ,StructField(\"_Title\", StringType(), True)\\\n",
    "                       ,StructField(\"_Tags\", StringType(), True)\\\n",
    "                       ,StructField(\"_AnswerCount\", StringType(), True)\\\n",
    "                       ,StructField(\"_CommentCount\", StringType(), True)\\\n",
    "                       ,StructField(\"_FavoriteCount\", StringType(), True)\\\n",
    "                       ,StructField(\"_LastEditorUserId\", StringType(), True)\\\n",
    "                       ,StructField(\"_AcceptedAnswerId\", StringType(), True)\\\n",
    "                       ,StructField(\"_LastEditDate\", StringType(), True)\\\n",
    "                       ,StructField(\"_ParentId\", StringType(), True)\\\n",
    "                       ,StructField(\"_Category\", StringType(), True)])\n",
    "testSchema = StructType([ StructField(\"_Id\", StringType(), True)\\\n",
    "                       ,StructField(\"_PostTypeId\", StringType(), True)\\\n",
    "                       ,StructField(\"_CreationDate\", StringType(), True)\\\n",
    "                       ,StructField(\"_Score\", StringType(), True)\\\n",
    "                       ,StructField(\"_ViewCount\", StringType(), True)\\\n",
    "                       ,StructField(\"_Body\", StringType(), True)\\\n",
    "                       ,StructField(\"_OwnerUserId\", StringType(), True)\\\n",
    "                       ,StructField(\"_LastActivityDate\", StringType(), True)\\\n",
    "                       ,StructField(\"_Title\", StringType(), True)\\\n",
    "                       ,StructField(\"_Tags\", StringType(), True)\\\n",
    "                       ,StructField(\"_AnswerCount\", StringType(), True)\\\n",
    "                       ,StructField(\"_CommentCount\", StringType(), True)\\\n",
    "                       ,StructField(\"_FavoriteCount\", StringType(), True)\\\n",
    "                       ,StructField(\"_LastEditorUserId\", StringType(), True)\\\n",
    "                       ,StructField(\"_AcceptedAnswerId\", StringType(), True)\\\n",
    "                       ,StructField(\"_LastEditDate\", StringType(), True)\\\n",
    "                       ,StructField(\"_ParentId\", StringType(), True)])\n",
    "train = session.createDataFrame(train,schema=mySchema)\n",
    "test = session.createDataFrame(test,schema=testSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_Id',\n",
       " '_PostTypeId',\n",
       " '_CreationDate',\n",
       " '_Score',\n",
       " '_ViewCount',\n",
       " '_Body',\n",
       " '_OwnerUserId',\n",
       " '_LastActivityDate',\n",
       " '_Title',\n",
       " '_Tags',\n",
       " '_AnswerCount',\n",
       " '_CommentCount',\n",
       " '_FavoriteCount',\n",
       " '_LastEditorUserId',\n",
       " '_AcceptedAnswerId',\n",
       " '_LastEditDate',\n",
       " '_ParentId']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|               _Body|_Category|\n",
      "+--------------------+---------+\n",
      "|Are questions rel...|   bricks|\n",
      "|What is a good ta...|   bricks|\n",
      "|I've asked one, s...|   bricks|\n",
      "|Lego Mindstorms a...|   bricks|\n",
      "|I suspect that Mi...|   bricks|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop the unnecessary columns \n",
    "drop_list = ['_Id', '_PostTypeId', '_CreationDate', '_Score', '_ViewCount', '_OwnerUserId', '_AnswerCount',\n",
    "             '_CommentCount', '_FavoriteCount', '_LastEditorUserId', '_AcceptedAnswerId', '_LastEditDate',\n",
    "             '_Tags', '_Title', '_ParentId', 'CreationDate', '_LastActivityDate', '_LastEditDate']\n",
    "\n",
    "train = train.select([column for column in train.columns if column not in drop_list])\n",
    "test = test.select([column for column in test.columns if column not in drop_list])\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _Body: string (nullable = true)\n",
      " |-- _Category: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|     _Category|count|\n",
      "+--------------+-----+\n",
      "|   arabic.meta|   11|\n",
      "|           avp|   10|\n",
      "|     agur.meta|   10|\n",
      "|        arabic|   10|\n",
      "|        bricks|   10|\n",
      "|          agur|   10|\n",
      "|    3dprinting|   10|\n",
      "|bioinformatics|   10|\n",
      "|            ai|    9|\n",
      "|          beer|    9|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# group by categories\n",
    "train.groupBy(\"_Category\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc() ) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression using Count Vector Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer \n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "# Raw data annotation  using document assesmber\n",
    "# documentAssembler = DocumentAssembler().setInputCol(\"_Body\").setOutputCol(\"document\")\n",
    "\n",
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"_Body\", outputCol=\"token\", pattern=\"\\\\W\")\n",
    "\n",
    "# stop words remover\n",
    "stop_words = list(stopwords.words('english'))\n",
    "[x.encode('utf-8') for x in stop_words]\n",
    "\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"token\", outputCol=\"filtered\").setStopWords(stop_words)\n",
    "\n",
    "# stemming the words\n",
    "#stemmer = Stemmer().setInputCols([\"stopFiltered\"]).setOutputCol(\"filtered\")\n",
    "\n",
    "# to show tokens in human language\n",
    "#finisher = Finisher().setInputCols([\"filtered\"])\n",
    "\n",
    "# bag of words count\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "label_stringIdx = StringIndexer(inputCol = \"_Category\", outputCol = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(train)\n",
    "dataset = pipelineFit.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+--------------------+-----+\n",
      "|               _Body|_Category|               token|            filtered|            features|label|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+-----+\n",
      "|Are questions rel...|   bricks|[are, questions, ...|[questions, relat...|(149,[0,1,9,14,31...|  6.0|\n",
      "|What is a good ta...|   bricks|[what, is, a, goo...|[good, tag, purch...|(149,[18,20,24,40...|  6.0|\n",
      "|I've asked one, s...|   bricks|[i, ve, asked, on...|[asked, one, let,...|(149,[7,10,54,55,...|  6.0|\n",
      "|Lego Mindstorms a...|   bricks|[lego, mindstorms...|[lego, mindstorms...|(149,[9,10,48,78,...|  6.0|\n",
      "|I suspect that Mi...|   bricks|[i, suspect, that...|[suspect, mindsto...|(149,[5,11,37,99]...|  6.0|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 67\n",
      "Test Dataset Count: 32\n"
     ]
    }
   ],
   "source": [
    "### Randomly split data into training and test sets. set seed for reproducibility\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "# Train model with Training Data\n",
    "lrModel = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------------+------------------------------+-----+----------+\n",
      "|                         _Body|     _Category|                   probability|label|prediction|\n",
      "+------------------------------+--------------+------------------------------+-----+----------+\n",
      "|I have a proposal - tool qu...|bioinformatics|[0.42239703411687485,0.1003...|  7.0|       0.0|\n",
      "|As discussed in the proposa...|   arabic.meta|[0.2461195377708617,0.02767...|  0.0|       7.0|\n",
      "|While allowing non-classica...|   arabic.meta|[0.12516369619240336,0.0810...|  0.0|       9.0|\n",
      "|The recommendation I made f...|   arabic.meta|[0.09746141150971549,0.2207...|  0.0|       5.0|\n",
      "|With foreign words, it seem...|        arabic|[0.09327622090526022,0.0734...|  5.0|       5.0|\n",
      "|I think your suggestion of ...|     agur.meta|[0.0922003785988423,0.07016...|  3.0|       3.0|\n",
      "|Since there's so many varie...|          beer|[0.0893719873598987,0.03829...|  8.0|       9.0|\n",
      "|I was about to ask a beginn...|           avp|[0.07523282376476899,0.0653...|  4.0|       4.0|\n",
      "|I'm already seeing a flood ...|        bricks|[0.07457956777429199,0.0661...|  6.0|       6.0|\n",
      "|Such open-ended question sh...|bioinformatics|[0.06674711634584385,0.0891...|  7.0|       9.0|\n",
      "+------------------------------+--------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "predictions.select(\"_Body\",\"_Category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39062500000000006"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_Body', 'token', 'filtered', 'features']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the transformations on test dataset(input_data.csv)\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors])\n",
    "\n",
    "# Fit the pipeline to testing documents.\n",
    "pipelineTrainFit = pipeline.fit(test)\n",
    "testDataset = pipelineFit.transform(test)\n",
    "testDataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+----------+\n",
      "|                         _Body|                   probability|prediction|\n",
      "+------------------------------+------------------------------+----------+\n",
      "|When I first saw this site,...|[0.33065033137249006,0.0065...|       9.0|\n",
      "|I have been thinking about ...|[0.26373920261779965,1.9255...|       9.0|\n",
      "|As discussed in the proposa...|[0.2461195377708617,0.02767...|       7.0|\n",
      "|There is no rule for this. ...|[0.21733248142421754,0.0592...|       5.0|\n",
      "|I recently posted this ques...|[0.18769205170915432,0.0639...|       6.0|\n",
      "|There are a few words that ...|[0.18247981079906478,0.1374...|       5.0|\n",
      "|This question is gathering ...|[0.1682867788998153,0.06583...|       8.0|\n",
      "|No, this will not insult an...|[0.16002323537979013,0.0734...|       5.0|\n",
      "|I think the obsolescence cy...|[0.1455522366884405,0.06839...|       9.0|\n",
      "|At the beginning of speech,...|[0.143730544523447,0.419216...|       1.0|\n",
      "+------------------------------+------------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting the categories for test dataset\n",
    "predictions = lrModel.transform(testDataset)\n",
    "\n",
    "predictions.filter(predictions['prediction'] != 0) \\\n",
    "    .select(\"_Body\",\"probability\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "# evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# Logistic Regression using TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "# Add HashingTF and IDF to transformation\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\")\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "\n",
    "# Redo Pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|               _Body|_Category|               token|            filtered|         rawFeatures|            features|label|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|Are questions rel...|   bricks|[are, questions, ...|[questions, relat...|(262144,[9559,152...|(262144,[9559,152...|  6.0|\n",
      "|What is a good ta...|   bricks|[what, is, a, goo...|[good, tag, purch...|(262144,[15664,35...|(262144,[15664,35...|  6.0|\n",
      "|I've asked one, s...|   bricks|[i, ve, asked, on...|[asked, one, let,...|(262144,[31463,53...|(262144,[31463,53...|  6.0|\n",
      "|Lego Mindstorms a...|   bricks|[lego, mindstorms...|[lego, mindstorms...|(262144,[38068,57...|(262144,[38068,57...|  6.0|\n",
      "|I suspect that Mi...|   bricks|[i, suspect, that...|[suspect, mindsto...|(262144,[47032,49...|(262144,[47032,49...|  6.0|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelineFit = pipeline.fit(train)\n",
    "dataset = pipelineFit.transform(train)\n",
    "### Randomly split data into training and test sets. set seed for reproducibility\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "\n",
    "# Build the model\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "# Train model with Training Data\n",
    "lrModel = lr.fit(trainingData)\n",
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------+------------------------------+-----+----------+\n",
      "|                         _Body|_Category|                   probability|label|prediction|\n",
      "+------------------------------+---------+------------------------------+-----+----------+\n",
      "|I have heard that Arabs did...|   arabic|[0.0909090909090909,0.10389...|  5.0|       2.0|\n",
      "|I think this is a good idea...|      avp|[0.0909090909090909,0.10389...|  4.0|       2.0|\n",
      "|I was about to ask a beginn...|      avp|[0.0909090909090909,0.10389...|  4.0|       2.0|\n",
      "|I've been waiting for this ...|      avp|[0.0909090909090909,0.10389...|  4.0|       2.0|\n",
      "|My advise would be that if ...|      avp|[0.0909090909090909,0.10389...|  4.0|       2.0|\n",
      "|Since there's so many varie...|     beer|[0.0909090909090909,0.10389...|  8.0|       2.0|\n",
      "|The Arabic alphabet lacks t...|   arabic|[0.0909090909090909,0.10389...|  5.0|       2.0|\n",
      "|With foreign words, it seem...|   arabic|[0.0909090909090909,0.10389...|  5.0|       2.0|\n",
      "|Are all trades published af...|     agur|[0.0909090909090909,0.10389...|  1.0|       2.0|\n",
      "|As far as the question is r...|agur.meta|[0.0909090909090909,0.10389...|  3.0|       2.0|\n",
      "+------------------------------+---------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "predictions.select(\"_Body\",\"_Category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007352941176470588"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation using Count Vector Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3853805916305917"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])\n",
    "\n",
    "pipelineFit = pipeline.fit(train)\n",
    "dataset = pipelineFit.transform(train)\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "\n",
    "# Build the model\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "# Run cross validations\n",
    "# cvModel uses the best model found from the Cross Validation\n",
    "cvModel = cv.fit(trainingData)\n",
    "\n",
    "# Test the model to measure the accuracy on new data\n",
    "predictions = cvModel.transform(testData)\n",
    "\n",
    "# Evaluate best model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-----------+------------------------------+-----+----------+\n",
      "|                         _Body|  _Category|                   probability|label|prediction|\n",
      "+------------------------------+-----------+------------------------------+-----+----------+\n",
      "|As discussed in the proposa...|arabic.meta|[0.9999999999712739,5.34425...|  0.0|       0.0|\n",
      "|While allowing non-classica...|arabic.meta|[0.9992658459820413,1.67714...|  0.0|       0.0|\n",
      "|Ù",
      "Ø§ Ø§ÙÙØ±Ù Ø¨ÙÙ Ø§Ù...|arabic.meta|[0.9986421823280933,2.61985...|  0.0|       0.0|\n",
      "|The Arabic alphabet lacks t...|     arabic|[0.6167785581497183,5.44033...|  5.0|       0.0|\n",
      "|So far most Augur SE answer...|  agur.meta|[0.24641193000535663,2.9074...|  3.0|       2.0|\n",
      "|It's simply too broad. What...|arabic.meta|[0.20860792513353935,0.0055...|  0.0|       9.0|\n",
      "|With foreign words, it seem...|     arabic|[0.19990976255238269,0.0079...|  5.0|       5.0|\n",
      "|My advise would be that if ...|        avp|[0.10912919293256443,3.4418...|  4.0|       2.0|\n",
      "|I was about to ask a beginn...|        avp|[0.10719186237808263,1.0803...|  4.0|       2.0|\n",
      "|In U.S. sports betting is i...|       agur|[0.09856336917433596,0.5587...|  1.0|       1.0|\n",
      "+------------------------------+-----------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "\n",
    "# train the model\n",
    "model = nb.fit(trainingData)\n",
    "\n",
    "\n",
    "predictions = model.transform(testData)\n",
    "predictions.select(\"_Body\",\"_Category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4359375"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-----------+------------------------------+-----+----------+\n",
      "|                         _Body|  _Category|                   probability|label|prediction|\n",
      "+------------------------------+-----------+------------------------------+-----+----------+\n",
      "|As discussed in the proposa...|arabic.meta|[0.9999999999712739,5.34425...|  0.0|       0.0|\n",
      "|While allowing non-classica...|arabic.meta|[0.9992658459820413,1.67714...|  0.0|       0.0|\n",
      "|Ù",
      "Ø§ Ø§ÙÙØ±Ù Ø¨ÙÙ Ø§Ù...|arabic.meta|[0.9986421823280933,2.61985...|  0.0|       0.0|\n",
      "|The Arabic alphabet lacks t...|     arabic|[0.6167785581497183,5.44033...|  5.0|       0.0|\n",
      "|So far most Augur SE answer...|  agur.meta|[0.24641193000535663,2.9074...|  3.0|       2.0|\n",
      "|It's simply too broad. What...|arabic.meta|[0.20860792513353935,0.0055...|  0.0|       9.0|\n",
      "|With foreign words, it seem...|     arabic|[0.19990976255238269,0.0079...|  5.0|       5.0|\n",
      "|My advise would be that if ...|        avp|[0.10912919293256443,3.4418...|  4.0|       2.0|\n",
      "|I was about to ask a beginn...|        avp|[0.10719186237808263,1.0803...|  4.0|       2.0|\n",
      "|In U.S. sports betting is i...|       agur|[0.09856336917433596,0.5587...|  1.0|       1.0|\n",
      "+------------------------------+-----------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Create an initial RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "\n",
    "# Train model with Training Data\n",
    "rfModel = rf.fit(trainingData)\n",
    "\n",
    "predictions = model.transform(testData)\n",
    "predictions.select(\"_Body\",\"_Category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4359375"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
